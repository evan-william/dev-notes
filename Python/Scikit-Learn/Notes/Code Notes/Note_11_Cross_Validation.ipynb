{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be57ec2-89df-4a54-9583-a4e697973d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9689955d-63fd-4b77-80a0-95b7841292b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled shape: (569, 30)\n",
      "y shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "# We scale features so all have similar ranges. This is important for KNN.\n",
    "# IMPORTANT: When using cross-validation, prefer applying scaling inside a Pipeline\n",
    "#            (see later). If you scale the entire dataset BEFORE cross-validation\n",
    "#            you will leak test-set statistics into the training folds.\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Example - this scales the whole dataset (OK for quick demo, but not ideal for CV if\n",
    "# you forget that this scaling used all the data). Best practice: use Pipeline so scaling\n",
    "# is applied *inside* each train fold only.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Quick shapes check (always good to check)\n",
    "print(\"X_scaled shape:\", X_scaled.shape)   # (n_samples, n_features)\n",
    "print(\"y shape:\", y.shape)                 # (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f0aca5-2d6b-44dd-bb9b-935ca9062fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (per-fold): [0.96491228 0.95614035 0.98245614 0.95614035 0.96460177]\n",
      "Mean score: 0.9648501785437045\n",
      "Std (score across folds): 0.009609970350036127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, GroupKFold, TimeSeriesSplit\n",
    "\n",
    "# Create the estimator (model)\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Basic usage:\n",
    "#   cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None,\n",
    "#                   n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs',\n",
    "#                   error_score=nan)\n",
    "#\n",
    "# KEY PARAMETERS explained:\n",
    "# - estimator : any sklearn estimator implementing fit/predict (e.g., KNeighborsClassifier()).\n",
    "# - X, y      : data and labels. X shape (n_samples, n_features), y shape (n_samples,).\n",
    "# - groups    : optional array-like (n_samples,) used for GroupKFold (samples in same group\n",
    "#               will not be split between train/test).\n",
    "# - scoring   : None (default) uses estimator.score (for classifiers => accuracy). You can pass:\n",
    "#               - a string (e.g. 'accuracy', 'f1_macro', 'roc_auc', 'neg_mean_squared_error')\n",
    "#               - a scorer callable from sklearn.metrics (use make_scorer)\n",
    "#               NOTE: for \"loss\" metrics sklearn uses negative values ('neg_mean_squared_error')\n",
    "#                     because cross_val_score always maximizes the returned score.\n",
    "# - cv        : controls how data is split into folds. Can be:\n",
    "#               - an integer (e.g., cv=5) => default split (StratifiedKFold for classification)\n",
    "#               - an explicit cross-validator object (e.g., StratifiedKFold(...), KFold(...))\n",
    "#               - an iterable of (train_index, test_index) pairs\n",
    "# - n_jobs    : number of jobs for parallelism. n_jobs=None (no parallel). n_jobs=-1 uses all cores.\n",
    "# - verbose   : printing verbosity (0 = quiet)\n",
    "# - pre_dispatch : controls how many jobs are created/queued for parallel execution\n",
    "# - error_score : value to assign if a fail occurs during fitting/predicting (default is np.nan)\n",
    "#\n",
    "# DEFAULT CV FOR CLASSIFICATION:\n",
    "# - If you pass cv=int (e.g. 5) and your problem is classification, sklearn uses StratifiedKFold\n",
    "#   by default. That means each fold preserves the class ratio (good when classes are imbalanced).\n",
    "#\n",
    "# EXAMPLES of cv objects:\n",
    "# - StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  -> preserves class distribution\n",
    "# - KFold(n_splits=5, shuffle=True, random_state=42)            -> for regression or balanced classes\n",
    "# - GroupKFold(n_splits=5)                                      -> use when samples have groups\n",
    "# - TimeSeriesSplit(n_splits=5)                                 -> for time-ordered data\n",
    "#\n",
    "# IMPORTANT: cross_val_score clones the estimator for each fold. The estimator instance you pass\n",
    "#            is not re-used across folds (sklearn does clone(estimator) internally).\n",
    "#\n",
    "# SIMPLE CALL (classification example, 5-fold):\n",
    "scores = cross_val_score(clf, X_scaled, y, cv=5, n_jobs=-1)  # default scoring = accuracy for classifiers\n",
    "# This returns an array with 5 scores (one per fold).\n",
    "#\n",
    "# Print raw fold scores + common summary stats\n",
    "print(\"Cross-validation scores (per-fold):\", scores)\n",
    "print(\"Mean score:\", scores.mean())\n",
    "print(\"Std (score across folds):\", scores.std())\n",
    "\n",
    "# -------------------------\n",
    "# Examples of other options\n",
    "# -------------------------\n",
    "# 1) Use StratifiedKFold explicitly (good to set shuffle & random_state)\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# scores = cross_val_score(clf, X_scaled, y, cv=skf)\n",
    "\n",
    "# 2) Evaluate a different metric (e.g., F1 macro)\n",
    "# scores_f1 = cross_val_score(clf, X_scaled, y, cv=5, scoring='f1_macro')\n",
    "\n",
    "# 3) Use cross_validate if you want train scores, fit times, and multiple metrics\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# results = cross_validate(clf, X_scaled, y, cv=5, scoring=['accuracy','f1_macro'], return_train_score=True)\n",
    "\n",
    "# 4) Use Pipeline to avoid leakage (preferred when you need scaling or feature transforms)\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "# scores_pipe = cross_val_score(pipe, X, y, cv=5)  # This scales inside each fold correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba81c8d-9962-4a42-84d6-c6737b7dd52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9648501785437045)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Can find the mean\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b0b398-05cd-4c7a-81b2-e44c7fd0944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-fold accuracy: [0.96491228 0.95614035 0.98245614 0.95614035 0.96460177]\n",
      "Mean accuracy: 0.9648501785437045\n",
      "Std deviation: 0.009609970350036127\n",
      "\n",
      "KFold splits (train -> test indices):\n",
      "Fold 1: train=[2, 3, 4, 5, 6, 7, 8, 9]  test=[0, 1]\n",
      "Fold 2: train=[0, 1, 4, 5, 6, 7, 8, 9]  test=[2, 3]\n",
      "Fold 3: train=[0, 1, 2, 3, 6, 7, 8, 9]  test=[4, 5]\n",
      "Fold 4: train=[0, 1, 2, 3, 4, 5, 8, 9]  test=[6, 7]\n",
      "Fold 5: train=[0, 1, 2, 3, 4, 5, 6, 7]  test=[8, 9]\n",
      "\n",
      "StratifiedKFold accuracy scores: [0.98245614 0.94736842 0.93859649 0.98245614 0.96460177]\n",
      "\n",
      "F1-macro scores: [0.96265968 0.95263814 0.98095556 0.95157591 0.96245847]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=====================================\n",
    "CROSS-VALIDATION EXPLAINED (BEGINNER)\n",
    "=====================================\n",
    "\n",
    "Quick summary:\n",
    "-------------\n",
    "cross_val_score(clf, X, y, cv=5) runs the model 5 times on different train/validation splits\n",
    "and returns 5 scores (one per split). Use the mean ± std of those scores to estimate model performance.\n",
    "\n",
    "What is Cross-Validation?\n",
    "-------------------------\n",
    "- Think of your dataset as a deck of cards.\n",
    "- Instead of doing one train/test split, CV splits the deck into `cv` equal piles (folds).\n",
    "- For cv=5: 5 folds → each round train on 4 folds, test on the remaining 1.\n",
    "- Repeat until each fold has been used once for testing.\n",
    "- Output: 5 scores → average them.\n",
    "\n",
    "Step-by-step for cv=5:\n",
    "----------------------\n",
    "- Fold1, Fold2, Fold3, Fold4, Fold5\n",
    "- Iteration 1: train=[2,3,4,5], validate=[1]\n",
    "- Iteration 2: train=[1,3,4,5], validate=[2]\n",
    "- Iteration 3: train=[1,2,4,5], validate=[3]\n",
    "- Iteration 4: train=[1,2,3,5], validate=[4]\n",
    "- Iteration 5: train=[1,2,3,4], validate=[5]\n",
    "\n",
    "Why useful?\n",
    "-----------\n",
    "- A single train/test split can be lucky or unlucky.\n",
    "- CV averages over multiple splits → more reliable estimate of performance.\n",
    "\n",
    "------------------------------------------------------------\n",
    "PARAMETERS of cross_val_score (explained in beginner English)\n",
    "------------------------------------------------------------\n",
    "cross_val_score(estimator, X, y, groups=None, scoring=None, cv=None,\n",
    "                n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs',\n",
    "                error_score=np.nan)\n",
    "\n",
    "- estimator: the model (e.g., KNeighborsClassifier()).\n",
    "- X, y: features (X: n_samples × n_features), labels (y: n_samples,).\n",
    "- groups: for GroupKFold (ensures samples from the same group stay together).\n",
    "- scoring: how to measure performance.\n",
    "    * Default = estimator.score (accuracy for classifiers).\n",
    "    * Can use: 'accuracy', 'f1_macro', 'roc_auc', 'neg_mean_squared_error', etc.\n",
    "    * Note: for loss metrics sklearn uses NEGATIVE values (so higher is better).\n",
    "- cv: how to split the data.\n",
    "    * int (e.g., 5): StratifiedKFold for classification, KFold for regression.\n",
    "    * Or a cross-validator object (StratifiedKFold, KFold, GroupKFold, TimeSeriesSplit).\n",
    "- n_jobs: parallelism. n_jobs=-1 uses all CPU cores.\n",
    "- error_score: value to assign if model fails (default NaN).\n",
    "\n",
    "Default CV rules:\n",
    "-----------------\n",
    "- Classification + cv=int → StratifiedKFold (preserves class ratio).\n",
    "- Regression + cv=int → KFold.\n",
    "\n",
    "Special CV types:\n",
    "-----------------\n",
    "- StratifiedKFold: keeps class ratios balanced.\n",
    "- KFold: random split (shuffle recommended).\n",
    "- GroupKFold: split by groups (e.g., patients, cities).\n",
    "- TimeSeriesSplit: for ordered (temporal) data.\n",
    "\n",
    "Important:\n",
    "----------\n",
    "- cross_val_score clones the estimator for each fold → your clf object is NOT reused.\n",
    "- Always use Pipelines if preprocessing (e.g., scaling) is needed → avoids data leakage.\n",
    "\n",
    "------------------------------------------------------------\n",
    "Interpreting results:\n",
    "------------------------------------------------------------\n",
    "scores = cross_val_score(...)\n",
    "Example output: [0.95, 0.93, 0.94, 0.92, 0.96]\n",
    "- Mean = 0.94 (central estimate)\n",
    "- Std = 0.01 (low variance, stable model)\n",
    "\n",
    "If Std is high → model is unstable across folds.\n",
    "\n",
    "------------------------------------------------------------\n",
    "BEST PRACTICES:\n",
    "------------------------------------------------------------\n",
    "- Use Pipeline for scaling/feature selection to avoid leakage.\n",
    "- Use StratifiedKFold for imbalanced classification.\n",
    "- Shuffle in KFold unless it's time series.\n",
    "- For time series → TimeSeriesSplit.\n",
    "- Common cv values: 5 or 10.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# ========================\n",
    "# Practical code examples\n",
    "# ========================\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Pipeline: scaling inside CV (avoids leakage)\n",
    "pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "\n",
    "# Basic cross_val_score usage\n",
    "scores = cross_val_score(pipe, X, y, cv=5, n_jobs=-1)  # default scoring=accuracy for classifier\n",
    "print(\"Per-fold accuracy:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Std deviation:\", scores.std())\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Example: show actual train/test splits for KFold\n",
    "# --------------------------------------------------\n",
    "X_small = np.arange(10)\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "print(\"\\nKFold splits (train -> test indices):\")\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X_small), 1):\n",
    "    print(f\"Fold {i}: train={train_idx.tolist()}  test={test_idx.tolist()}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Example: StratifiedKFold with shuffling\n",
    "# --------------------------------------------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_strat = cross_val_score(pipe, X, y, cv=skf, n_jobs=-1)\n",
    "print(\"\\nStratifiedKFold accuracy scores:\", scores_strat)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Example: different metric (F1 macro)\n",
    "# --------------------------------------------------\n",
    "scores_f1 = cross_val_score(pipe, X, y, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "print(\"\\nF1-macro scores:\", scores_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec942b-ca2d-40b6-bda0-08188beb7769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
