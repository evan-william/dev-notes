{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b687eddc-71d0-420c-8b41-0a95f4121030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 1: What is a Pipeline?\n",
    "# ==========================================================\n",
    "# A Pipeline in sklearn is a way to chain multiple steps together\n",
    "# (like preprocessing + model) into a single object.\n",
    "#\n",
    "# Why is this useful?\n",
    "# - Cleaner code: instead of calling scaler.fit_transform(), then model.fit(), etc\n",
    "#   we put them into one pipeline.\n",
    "# - Consistency: ensures that the exact same preprocessing happens during training\n",
    "#   and prediction/testing.\n",
    "# - Cross-validation ready: avoids \"data leakage\" by making sure preprocessing\n",
    "#   is fit only on training folds, not on test folds.\n",
    "#\n",
    "# Structure:\n",
    "#   Pipeline([\n",
    "#       ('step_name1', transformer1),\n",
    "#       ('step_name2', transformer2),\n",
    "#       ('model', estimator)\n",
    "#   ])\n",
    "#\n",
    "# Notes:\n",
    "# - Each step except the last must be a transformer (something with fit/transform).\n",
    "# - The last step must be an estimator (classifier/regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e04727-a8e3-4073-a12f-4bc5e6952681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 2: Example Dataset Setup\n",
    "# ==========================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41bd293b-a618-4950-9914-de4356c2634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 3: Basic Pipeline Example\n",
    "# ==========================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline:\n",
    "# Step 1: scale the features (important for KNN)\n",
    "# Step 2: fit a KNeighborsClassifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),          # preprocessing step\n",
    "    ('knn', KNeighborsClassifier())        # model step\n",
    "])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the same pipeline\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# The scaler is automatically applied inside the pipeline\n",
    "# -> No need to manually scale test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc83237-96c7-4626-a4c2-110bdfaeb12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96491228, 0.95614035, 0.98245614, 0.95614035, 0.96460177])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 4: Pipeline with Cross-Validation\n",
    "# ==========================================================\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# We can directly pass the pipeline into cross_val_score\n",
    "scores = cross_val_score(pipe, X, y, cv=5)\n",
    "\n",
    "scores\n",
    "\n",
    "# Notes:\n",
    "# - cross_val_score automatically applies scaling inside each fold.\n",
    "# - This prevents data leakage (test fold data is never used for fitting scaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ceacf88-7268-4499-9add-2f92f9a4f927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 5, 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 5: Pipeline with Hyperparameter Tuning\n",
    "# ==========================================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for pipeline\n",
    "# IMPORTANT: to tune parameters inside a pipeline, we use \"stepname__parameter\"\n",
    "# Example: 'knn__n_neighbors' -> access n_neighbors inside 'knn' step\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV on the pipeline\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "# Notes:\n",
    "# - Pipeline allows us to combine preprocessing + model + hyperparameter tuning.\n",
    "# - Very powerful because everything is packaged together cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecaa07a-944f-40e2-a007-dd33ef6fa330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 6: Evaluate Best Pipeline\n",
    "# ==========================================================\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get best model (pipeline with best hyperparameters)\n",
    "best_pipe = grid.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_best = best_pipe.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "accuracy\n",
    "\n",
    "# Notes:\n",
    "# - The returned best estimator is STILL a pipeline.\n",
    "# - That means preprocessing + best model steps are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39750f6-327b-40f9-83cf-a8e4bdad9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 7: Summary of Pipelines\n",
    "# ==========================================================\n",
    "# ✅ Key Takeaways:\n",
    "# - Pipelines chain multiple steps (scaling, encoding, model, etc).\n",
    "# - Each step has a name + transformer/estimator.\n",
    "# - Final step must be a model (classifier/regressor).\n",
    "#\n",
    "# ✅ Benefits:\n",
    "# - Prevents data leakage\n",
    "# - Cleaner and more reproducible code\n",
    "# - Easy integration with cross-validation and GridSearchCV\n",
    "# - Automatically applies preprocessing at both training and prediction time\n",
    "#\n",
    "# ✅ Usage:\n",
    "# - Use when your model requires preprocessing.\n",
    "# - Combine with hyperparameter tuning for professional workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
